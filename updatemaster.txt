ansible-playbook [core 2.11.1] 
  config file = /home/macharyaainsigh/Easypay-capstone/ansible.cfg
  configured module search path = ['/home/macharyaainsigh/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/macharyaainsigh/.local/lib/python3.9/site-packages/ansible
  ansible collection location = /home/macharyaainsigh/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible-playbook
  python version = 3.9.4 (default, Apr  9 2021, 01:15:05) [GCC 5.4.0 20160609]
  jinja version = 2.8
  libyaml = False
Using /home/macharyaainsigh/Easypay-capstone/ansible.cfg as config file
host_list declined parsing /home/macharyaainsigh/hosts as it did not pass its verify_file() method
script declined parsing /home/macharyaainsigh/hosts as it did not pass its verify_file() method
auto declined parsing /home/macharyaainsigh/hosts as it did not pass its verify_file() method
Parsed /home/macharyaainsigh/hosts inventory source with ini plugin
Skipping callback 'default', as we already have a stdout callback.
Skipping callback 'minimal', as we already have a stdout callback.
Skipping callback 'oneline', as we already have a stdout callback.

PLAYBOOK: updatemaster.yml *****************************************************
1 plays in updatemaster.yml

PLAY [masters] *****************************************************************

TASK [Gathering Facts] *********************************************************
task path: /home/macharyaainsigh/Easypay-capstone/updatemaster.yml:2
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b 3.94.129.121 '/bin/sh -c '"'"'echo ~ubuntu && sleep 0'"'"''
<3.94.129.121> (0, b'/home/ubuntu\n', b'')
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b 3.94.129.121 '/bin/sh -c '"'"'( umask 77 && mkdir -p "` echo /home/ubuntu/.ansible/tmp `"&& mkdir "` echo /home/ubuntu/.ansible/tmp/ansible-tmp-1622902716.6685963-880-251761966657321 `" && echo ansible-tmp-1622902716.6685963-880-251761966657321="` echo /home/ubuntu/.ansible/tmp/ansible-tmp-1622902716.6685963-880-251761966657321 `" ) && sleep 0'"'"''
<3.94.129.121> (0, b'ansible-tmp-1622902716.6685963-880-251761966657321=/home/ubuntu/.ansible/tmp/ansible-tmp-1622902716.6685963-880-251761966657321\n', b'')
<3.94.129.121> Attempting python interpreter discovery
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b 3.94.129.121 '/bin/sh -c '"'"'echo PLATFORM; uname; echo FOUND; command -v '"'"'"'"'"'"'"'"'/usr/bin/python'"'"'"'"'"'"'"'"'; command -v '"'"'"'"'"'"'"'"'python3.9'"'"'"'"'"'"'"'"'; command -v '"'"'"'"'"'"'"'"'python3.8'"'"'"'"'"'"'"'"'; command -v '"'"'"'"'"'"'"'"'python3.7'"'"'"'"'"'"'"'"'; command -v '"'"'"'"'"'"'"'"'python3.6'"'"'"'"'"'"'"'"'; command -v '"'"'"'"'"'"'"'"'python3.5'"'"'"'"'"'"'"'"'; command -v '"'"'"'"'"'"'"'"'python2.7'"'"'"'"'"'"'"'"'; command -v '"'"'"'"'"'"'"'"'python2.6'"'"'"'"'"'"'"'"'; command -v '"'"'"'"'"'"'"'"'/usr/libexec/platform-python'"'"'"'"'"'"'"'"'; command -v '"'"'"'"'"'"'"'"'/usr/bin/python3'"'"'"'"'"'"'"'"'; command -v '"'"'"'"'"'"'"'"'python'"'"'"'"'"'"'"'"'; echo ENDFOUND && sleep 0'"'"''
<3.94.129.121> (0, b'PLATFORM\nLinux\nFOUND\n/usr/bin/python3.8\n/usr/bin/python3\nENDFOUND\n', b'')
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b 3.94.129.121 '/bin/sh -c '"'"'/usr/bin/python3.8 && sleep 0'"'"''
<3.94.129.121> (0, b'{"platform_dist_result": [], "osrelease_content": "NAME=\\"Ubuntu\\"\\nVERSION=\\"20.04.2 LTS (Focal Fossa)\\"\\nID=ubuntu\\nID_LIKE=debian\\nPRETTY_NAME=\\"Ubuntu 20.04.2 LTS\\"\\nVERSION_ID=\\"20.04\\"\\nHOME_URL=\\"https://www.ubuntu.com/\\"\\nSUPPORT_URL=\\"https://help.ubuntu.com/\\"\\nBUG_REPORT_URL=\\"https://bugs.launchpad.net/ubuntu/\\"\\nPRIVACY_POLICY_URL=\\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\\"\\nVERSION_CODENAME=focal\\nUBUNTU_CODENAME=focal\\n"}\n', b'')
Using module file /home/macharyaainsigh/.local/lib/python3.9/site-packages/ansible/modules/setup.py
<3.94.129.121> PUT /home/macharyaainsigh/.ansible/tmp/ansible-local-31018ld70xt74/tmp8ydbz0cn TO /home/ubuntu/.ansible/tmp/ansible-tmp-1622902716.6685963-880-251761966657321/AnsiballZ_setup.py
<3.94.129.121> SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b '[3.94.129.121]'
<3.94.129.121> (0, b'sftp> put /home/macharyaainsigh/.ansible/tmp/ansible-local-31018ld70xt74/tmp8ydbz0cn /home/ubuntu/.ansible/tmp/ansible-tmp-1622902716.6685963-880-251761966657321/AnsiballZ_setup.py\n', b'')
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b 3.94.129.121 '/bin/sh -c '"'"'chmod u+x /home/ubuntu/.ansible/tmp/ansible-tmp-1622902716.6685963-880-251761966657321/ /home/ubuntu/.ansible/tmp/ansible-tmp-1622902716.6685963-880-251761966657321/AnsiballZ_setup.py && sleep 0'"'"''
<3.94.129.121> (0, b'', b'')
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b -tt 3.94.129.121 '/bin/sh -c '"'"'sudo -H -S -n  -u root /bin/sh -c '"'"'"'"'"'"'"'"'echo BECOME-SUCCESS-tlufahqpsistylfoveucivltoxethdts ; /usr/bin/python3 /home/ubuntu/.ansible/tmp/ansible-tmp-1622902716.6685963-880-251761966657321/AnsiballZ_setup.py'"'"'"'"'"'"'"'"' && sleep 0'"'"''
Escalation succeeded
<3.94.129.121> (0, b'\r\n{"ansible_facts": {"ansible_user_id": "root", "ansible_user_uid": 0, "ansible_user_gid": 0, "ansible_user_gecos": "root", "ansible_user_dir": "/root", "ansible_user_shell": "/bin/bash", "ansible_real_user_id": 0, "ansible_effective_user_id": 0, "ansible_real_group_id": 0, "ansible_effective_group_id": 0, "ansible_is_chroot": false, "ansible_distribution": "Ubuntu", "ansible_distribution_release": "focal", "ansible_distribution_version": "20.04", "ansible_distribution_major_version": "20", "ansible_distribution_file_path": "/etc/os-release", "ansible_distribution_file_variety": "Debian", "ansible_distribution_file_parsed": true, "ansible_os_family": "Debian", "ansible_iscsi_iqn": "", "ansible_ssh_host_key_dsa_public": "AAAAB3NzaC1kc3MAAACBAJgLvW1ktvj9u8P8gT+O+7RoadzeNLHhQV39uzWS27IQDD0lWEHRkKSy5vlX0IGocVsXt5yGjHVTxdeG4IdCeQ97enX3yZGJIl38egPASQl1vNVdsRLYf/D0HEFs1LxY9cyCkpju0yHUj4SWxPwn0SYEODmXZ7iSFiS3YBx2PZ3lAAAAFQCtl3hbDG18qD0RNPAPNakaXn4sEwAAAIA8BLQxhi2DtXDZKoE1kBAy6Tn+x5rpD9ZVYbRViWD4llfEss/buyWbJbYF5Cf6gOW1OnaCIfz/S/jON4QNMiilYDNBDHahKWlk0vmmOGdkXp6pb46JAdcORb1Unfi2j5P+fym4IcM5jrPSD2Q/dG7d18mGJmx9fQNoje06scvlDQAAAIAyj4SUb8eHPt3gDOgIYCz62lXjlollrB306cqWwNnpAG4RRXM4zc3Pv6bmsR1nAXknBf+V2UFaEtNnTJpwroEuGpga2LCs1fGMHSlyG2hOBsZFoGqPLrM2zrXqtkXx07Z9kMHszeNUZjKQ9sYhIhOgv016MZp0Hcpwg5UCvK2vFA==", "ansible_ssh_host_key_dsa_public_keytype": "ssh-dss", "ansible_ssh_host_key_rsa_public": "AAAAB3NzaC1yc2EAAAADAQABAAABgQDVb0SNIys6ga0a7aiiR5x0lRaI/A8aAA/3K9QgK0i3ieQm8wtTKuVCCnRGkINF+yJJJbjQW3Eyu5zfISInzhZ+wmkfe42vXCxOo7p/R3SQ19I6lMCInti4mgUikLMK1Xefv83/Ao3g+2PshqdavSNtrmSgp3uQtlfbxXV0HKnVOceBA4tCr1qkGOddkEMOOOhhjsP7/HIVOnosTLAdntbLbKghBNBuLld3KFBSC2SdYxB25iVuBjpUyRFN67nFUWDG1ySdxcKGmJrY+pLEj7W1DzMHqtjQSIK8NFqE2C4HNV6u6RvLGfy2vEpdzpG9XLBWjamTqJrBdVkcRx2UrFffXqCXM9S3rcdx0feUM4CZXk2wO4nBEVnXKFDAGq7y2b7Lc+kxuZaSZY7KA1XTlseGNKFImHoLSprdELxAlMcZBtS1wcxvf0rCot+d95UQFpznV46EB+G00gu66N0sdEiOwdEqD79cX1iy0nvD63Q35JNZw7/OJLqxJ3fQbslVhW8=", "ansible_ssh_host_key_rsa_public_keytype": "ssh-rsa", "ansible_ssh_host_key_ecdsa_public": "AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBEIxayyZ0Jr11PNZ5p1EdSWEwHZP38cdKf0kqWHyTtHIN6+jbke6Kuf8g7IK8Nxeyqggrn+2tlsXjQ4gMaA/6lc=", "ansible_ssh_host_key_ecdsa_public_keytype": "ecdsa-sha2-nistp256", "ansible_ssh_host_key_ed25519_public": "AAAAC3NzaC1lZDI1NTE5AAAAIAEBix3aCOcQn4sZ+5Xbkb6JXsbmdi0JDV44MHAHKGbn", "ansible_ssh_host_key_ed25519_public_keytype": "ssh-ed25519", "ansible_lsb": {"id": "Ubuntu", "description": "Ubuntu 20.04.2 LTS", "release": "20.04", "codename": "focal", "major_release": "20"}, "ansible_fibre_channel_wwn": [], "ansible_system": "Linux", "ansible_kernel": "5.4.0-1045-aws", "ansible_kernel_version": "#47-Ubuntu SMP Tue Apr 13 07:02:25 UTC 2021", "ansible_machine": "x86_64", "ansible_python_version": "3.8.5", "ansible_fqdn": "ip-172-10-1-95.ec2.internal", "ansible_hostname": "ip-172-10-1-95", "ansible_nodename": "ip-172-10-1-95", "ansible_domain": "ec2.internal", "ansible_userspace_bits": "64", "ansible_architecture": "x86_64", "ansible_userspace_architecture": "x86_64", "ansible_machine_id": "ec29214b87fe2afdb319a851f49e38cd", "ansible_pkg_mgr": "apt", "ansible_processor": ["0", "GenuineIntel", "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz", "1", "GenuineIntel", "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz"], "ansible_processor_count": 1, "ansible_processor_cores": 1, "ansible_processor_threads_per_core": 2, "ansible_processor_vcpus": 2, "ansible_processor_nproc": 2, "ansible_memtotal_mb": 953, "ansible_memfree_mb": 137, "ansible_swaptotal_mb": 0, "ansible_swapfree_mb": 0, "ansible_memory_mb": {"real": {"total": 953, "used": 816, "free": 137}, "nocache": {"free": 680, "used": 273}, "swap": {"total": 0, "free": 0, "used": 0, "cached": 0}}, "ansible_bios_date": "10/16/2017", "ansible_bios_vendor": "Amazon EC2", "ansible_bios_version": "1.0", "ansible_board_asset_tag": "i-060e8a2bd9e791a85", "ansible_board_name": "NA", "ansible_board_serial": "NA", "ansible_board_vendor": "Amazon EC2", "ansible_board_version": "NA", "ansible_chassis_asset_tag": "Amazon EC2", "ansible_chassis_serial": "NA", "ansible_chassis_vendor": "Amazon EC2", "ansible_chassis_version": "NA", "ansible_form_factor": "Other", "ansible_product_name": "t3.micro", "ansible_product_serial": "ec29214b-87fe-2afd-b319-a851f49e38cd", "ansible_product_uuid": "ec29214b-87fe-2afd-b319-a851f49e38cd", "ansible_product_version": "NA", "ansible_system_vendor": "Amazon EC2", "ansible_devices": {"loop1": {"virtual": 1, "links": {"ids": [], "uuids": [], "labels": [], "masters": []}, "vendor": null, "model": null, "sas_address": null, "sas_device_handle": null, "removable": "0", "support_discard": "4096", "partitions": {}, "rotational": "0", "scheduler_mode": "mq-deadline", "sectors": "113560", "sectorsize": "512", "size": "55.45 MB", "host": "", "holders": []}, "nvme0n1": {"virtual": 1, "links": {"ids": ["nvme-Amazon_Elastic_Block_Store_vol0c3e69b007eb40146", "nvme-nvme.1d0f-766f6c3063336536396230303765623430313436-416d617a6f6e20456c617374696320426c6f636b2053746f7265-00000001"], "uuids": [], "labels": [], "masters": []}, "vendor": null, "model": "Amazon Elastic Block Store", "sas_address": null, "sas_device_handle": null, "removable": "0", "support_discard": "0", "partitions": {"nvme0n1p1": {"links": {"ids": ["nvme-Amazon_Elastic_Block_Store_vol0c3e69b007eb40146-part1", "nvme-nvme.1d0f-766f6c3063336536396230303765623430313436-416d617a6f6e20456c617374696320426c6f636b2053746f7265-00000001-part1"], "uuids": ["e8070c31-bfee-4314-a151-d1332dc23486"], "labels": ["cloudimg-rootfs"], "masters": []}, "start": "2048", "sectors": "16775135", "sectorsize": 512, "size": "8.00 GB", "uuid": "e8070c31-bfee-4314-a151-d1332dc23486", "holders": []}}, "rotational": "0", "scheduler_mode": "none", "sectors": "16777216", "sectorsize": "512", "size": "8.00 GB", "host": "Non-Volatile memory controller: Amazon.com, Inc. Device 8061", "holders": []}, "loop6": {"virtual": 1, "links": {"ids": [], "uuids": [], "labels": [], "masters": []}, "vendor": null, "model": null, "sas_address": null, "sas_device_handle": null, "removable": "0", "support_discard": "0", "partitions": {}, "rotational": "1", "scheduler_mode": "mq-deadline", "sectors": "0", "sectorsize": "512", "size": "0.00 Bytes", "host": "", "holders": []}, "loop4": {"virtual": 1, "links": {"ids": [], "uuids": [], "labels": [], "masters": []}, "vendor": null, "model": null, "sas_address": null, "sas_device_handle": null, "removable": "0", "support_discard": "4096", "partitions": {}, "rotational": "0", "scheduler_mode": "mq-deadline", "sectors": "0", "sectorsize": "512", "size": "0.00 Bytes", "host": "", "holders": []}, "md0": {"virtual": 1, "links": {"ids": [], "uuids": [], "labels": [], "masters": []}, "vendor": null, "model": null, "sas_address": null, "sas_device_handle": null, "removable": "0", "support_discard": "0", "partitions": {}, "rotational": "1", "scheduler_mode": "", "sectors": "0", "sectorsize": "512", "size": "0.00 Bytes", "host": "", "holders": []}, "loop2": {"virtual": 1, "links": {"ids": [], "uuids": [], "labels": [], "masters": []}, "vendor": null, "model": null, "sas_address": null, "sas_device_handle": null, "removable": "0", "support_discard": "4096", "partitions": {}, "rotational": "0", "scheduler_mode": "mq-deadline", "sectors": "144136", "sectorsize": "512", "size": "70.38 MB", "host": "", "holders": []}, "loop0": {"virtual": 1, "links": {"ids": [], "uuids": [], "labels": [], "masters": []}, "vendor": null, "model": null, "sas_address": null, "sas_device_handle": null, "removable": "0", "support_discard": "4096", "partitions": {}, "rotational": "0", "scheduler_mode": "mq-deadline", "sectors": "68280", "sectorsize": "512", "size": "33.34 MB", "host": "", "holders": []}, "loop7": {"virtual": 1, "links": {"ids": [], "uuids": [], "labels": [], "masters": []}, "vendor": null, "model": null, "sas_address": null, "sas_device_handle": null, "removable": "0", "support_discard": "0", "partitions": {}, "rotational": "1", "scheduler_mode": "mq-deadline", "sectors": "0", "sectorsize": "512", "size": "0.00 Bytes", "host": "", "holders": []}, "loop5": {"virtual": 1, "links": {"ids": [], "uuids": [], "labels": [], "masters": []}, "vendor": null, "model": null, "sas_address": null, "sas_device_handle": null, "removable": "0", "support_discard": "0", "partitions": {}, "rotational": "1", "scheduler_mode": "mq-deadline", "sectors": "0", "sectorsize": "512", "size": "0.00 Bytes", "host": "", "holders": []}, "loop3": {"virtual": 1, "links": {"ids": [], "uuids": [], "labels": [], "masters": []}, "vendor": null, "model": null, "sas_address": null, "sas_device_handle": null, "removable": "0", "support_discard": "4096", "partitions": {}, "rotational": "0", "scheduler_mode": "mq-deadline", "sectors": "66096", "sectorsize": "512", "size": "32.27 MB", "host": "", "holders": []}}, "ansible_device_links": {"ids": {"nvme0n1p1": ["nvme-Amazon_Elastic_Block_Store_vol0c3e69b007eb40146-part1", "nvme-nvme.1d0f-766f6c3063336536396230303765623430313436-416d617a6f6e20456c617374696320426c6f636b2053746f7265-00000001-part1"], "nvme0n1": ["nvme-Amazon_Elastic_Block_Store_vol0c3e69b007eb40146", "nvme-nvme.1d0f-766f6c3063336536396230303765623430313436-416d617a6f6e20456c617374696320426c6f636b2053746f7265-00000001"]}, "uuids": {"nvme0n1p1": ["e8070c31-bfee-4314-a151-d1332dc23486"]}, "labels": {"nvme0n1p1": ["cloudimg-rootfs"]}, "masters": {}}, "ansible_uptime_seconds": 153, "ansible_lvm": {"lvs": {}, "vgs": {}, "pvs": {}}, "ansible_mounts": [{"mount": "/", "device": "/dev/root", "fstype": "ext4", "options": "rw,relatime,discard", "size_total": 8259014656, "size_available": 5756289024, "block_size": 4096, "block_total": 2016361, "block_available": 1405344, "block_used": 611017, "inode_total": 1024000, "inode_available": 954464, "inode_used": 69536, "uuid": "e8070c31-bfee-4314-a151-d1332dc23486"}, {"mount": "/snap/core18/1997", "device": "/dev/loop1", "fstype": "squashfs", "options": "ro,nodev,relatime", "size_total": 58195968, "size_available": 0, "block_size": 131072, "block_total": 444, "block_available": 0, "block_used": 444, "inode_total": 10790, "inode_available": 0, "inode_used": 10790, "uuid": "N/A"}, {"mount": "/snap/amazon-ssm-agent/3552", "device": "/dev/loop0", "fstype": "squashfs", "options": "ro,nodev,relatime", "size_total": 34996224, "size_available": 0, "block_size": 131072, "block_total": 267, "block_available": 0, "block_used": 267, "inode_total": 16, "inode_available": 0, "inode_used": 16, "uuid": "N/A"}, {"mount": "/snap/snapd/11588", "device": "/dev/loop3", "fstype": "squashfs", "options": "ro,nodev,relatime", "size_total": 33947648, "size_available": 0, "block_size": 131072, "block_total": 259, "block_available": 0, "block_used": 259, "inode_total": 474, "inode_available": 0, "inode_used": 474, "uuid": "N/A"}, {"mount": "/snap/lxd/19647", "device": "/dev/loop2", "fstype": "squashfs", "options": "ro,nodev,relatime", "size_total": 73924608, "size_available": 0, "block_size": 131072, "block_total": 564, "block_available": 0, "block_used": 564, "inode_total": 1578, "inode_available": 0, "inode_used": 1578, "uuid": "N/A"}], "ansible_service_mgr": "systemd", "ansible_virtualization_role": "guest", "ansible_virtualization_type": "kvm", "ansible_virtualization_tech_guest": ["kvm"], "ansible_virtualization_tech_host": [], "ansible_env": {"SUDO_GID": "1000", "MAIL": "/var/mail/root", "USER": "root", "HOME": "/root", "SUDO_UID": "1000", "LOGNAME": "root", "TERM": "xterm", "PATH": "/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin", "LANG": "C.UTF-8", "SUDO_COMMAND": "/bin/sh -c echo BECOME-SUCCESS-tlufahqpsistylfoveucivltoxethdts ; /usr/bin/python3 /home/ubuntu/.ansible/tmp/ansible-tmp-1622902716.6685963-880-251761966657321/AnsiballZ_setup.py", "SHELL": "/bin/bash", "SUDO_USER": "ubuntu", "PWD": "/home/ubuntu"}, "ansible_hostnqn": "", "ansible_system_capabilities_enforced": "False", "ansible_system_capabilities": [], "ansible_cmdline": {"BOOT_IMAGE": "/boot/vmlinuz-5.4.0-1045-aws", "root": "PARTUUID=5198cbc0-01", "ro": true, "console": "ttyS0", "nvme_core.io_timeout": "4294967295", "panic": "-1"}, "ansible_proc_cmdline": {"BOOT_IMAGE": "/boot/vmlinuz-5.4.0-1045-aws", "root": "PARTUUID=5198cbc0-01", "ro": true, "console": ["tty1", "ttyS0"], "nvme_core.io_timeout": "4294967295", "panic": "-1"}, "ansible_interfaces": ["ens5", "docker0", "lo"], "ansible_lo": {"device": "lo", "mtu": 65536, "active": true, "type": "loopback", "promisc": false, "ipv4": {"address": "127.0.0.1", "broadcast": "", "netmask": "255.0.0.0", "network": "127.0.0.0"}, "ipv6": [{"address": "::1", "prefix": "128", "scope": "host"}], "features": {"rx_checksumming": "on [fixed]", "tx_checksumming": "on", "tx_checksum_ipv4": "off [fixed]", "tx_checksum_ip_generic": "on [fixed]", "tx_checksum_ipv6": "off [fixed]", "tx_checksum_fcoe_crc": "off [fixed]", "tx_checksum_sctp": "on [fixed]", "scatter_gather": "on", "tx_scatter_gather": "on [fixed]", "tx_scatter_gather_fraglist": "on [fixed]", "tcp_segmentation_offload": "on", "tx_tcp_segmentation": "on", "tx_tcp_ecn_segmentation": "on", "tx_tcp_mangleid_segmentation": "on", "tx_tcp6_segmentation": "on", "generic_segmentation_offload": "on", "generic_receive_offload": "on", "large_receive_offload": "off [fixed]", "rx_vlan_offload": "off [fixed]", "tx_vlan_offload": "off [fixed]", "ntuple_filters": "off [fixed]", "receive_hashing": "off [fixed]", "highdma": "on [fixed]", "rx_vlan_filter": "off [fixed]", "vlan_challenged": "on [fixed]", "tx_lockless": "on [fixed]", "netns_local": "on [fixed]", "tx_gso_robust": "off [fixed]", "tx_fcoe_segmentation": "off [fixed]", "tx_gre_segmentation": "off [fixed]", "tx_gre_csum_segmentation": "off [fixed]", "tx_ipxip4_segmentation": "off [fixed]", "tx_ipxip6_segmentation": "off [fixed]", "tx_udp_tnl_segmentation": "off [fixed]", "tx_udp_tnl_csum_segmentation": "off [fixed]", "tx_gso_partial": "off [fixed]", "tx_sctp_segmentation": "on", "tx_esp_segmentation": "off [fixed]", "tx_udp_segmentation": "off [fixed]", "fcoe_mtu": "off [fixed]", "tx_nocache_copy": "off [fixed]", "loopback": "on [fixed]", "rx_fcs": "off [fixed]", "rx_all": "off [fixed]", "tx_vlan_stag_hw_insert": "off [fixed]", "rx_vlan_stag_hw_parse": "off [fixed]", "rx_vlan_stag_filter": "off [fixed]", "l2_fwd_offload": "off [fixed]", "hw_tc_offload": "off [fixed]", "esp_hw_offload": "off [fixed]", "esp_tx_csum_hw_offload": "off [fixed]", "rx_udp_tunnel_port_offload": "off [fixed]", "tls_hw_tx_offload": "off [fixed]", "tls_hw_rx_offload": "off [fixed]", "rx_gro_hw": "off [fixed]", "tls_hw_record": "off [fixed]"}, "timestamping": ["tx_software", "rx_software", "software"], "hw_timestamp_filters": []}, "ansible_docker0": {"device": "docker0", "macaddress": "02:42:3c:dd:be:fe", "mtu": 1500, "active": false, "type": "bridge", "interfaces": [], "id": "8000.02423cddbefe", "stp": false, "promisc": false, "ipv4": {"address": "172.17.0.1", "broadcast": "172.17.255.255", "netmask": "255.255.0.0", "network": "172.17.0.0"}, "features": {"rx_checksumming": "off [fixed]", "tx_checksumming": "on", "tx_checksum_ipv4": "off [fixed]", "tx_checksum_ip_generic": "on", "tx_checksum_ipv6": "off [fixed]", "tx_checksum_fcoe_crc": "off [fixed]", "tx_checksum_sctp": "off [fixed]", "scatter_gather": "on", "tx_scatter_gather": "on", "tx_scatter_gather_fraglist": "on", "tcp_segmentation_offload": "on", "tx_tcp_segmentation": "on", "tx_tcp_ecn_segmentation": "on", "tx_tcp_mangleid_segmentation": "on", "tx_tcp6_segmentation": "on", "generic_segmentation_offload": "on", "generic_receive_offload": "on", "large_receive_offload": "off [fixed]", "rx_vlan_offload": "off [fixed]", "tx_vlan_offload": "on", "ntuple_filters": "off [fixed]", "receive_hashing": "off [fixed]", "highdma": "on", "rx_vlan_filter": "off [fixed]", "vlan_challenged": "off [fixed]", "tx_lockless": "on [fixed]", "netns_local": "on [fixed]", "tx_gso_robust": "on", "tx_fcoe_segmentation": "on", "tx_gre_segmentation": "on", "tx_gre_csum_segmentation": "on", "tx_ipxip4_segmentation": "on", "tx_ipxip6_segmentation": "on", "tx_udp_tnl_segmentation": "on", "tx_udp_tnl_csum_segmentation": "on", "tx_gso_partial": "on", "tx_sctp_segmentation": "on", "tx_esp_segmentation": "on", "tx_udp_segmentation": "on", "fcoe_mtu": "off [fixed]", "tx_nocache_copy": "off", "loopback": "off [fixed]", "rx_fcs": "off [fixed]", "rx_all": "off [fixed]", "tx_vlan_stag_hw_insert": "on", "rx_vlan_stag_hw_parse": "off [fixed]", "rx_vlan_stag_filter": "off [fixed]", "l2_fwd_offload": "off [fixed]", "hw_tc_offload": "off [fixed]", "esp_hw_offload": "off [fixed]", "esp_tx_csum_hw_offload": "off [fixed]", "rx_udp_tunnel_port_offload": "off [fixed]", "tls_hw_tx_offload": "off [fixed]", "tls_hw_rx_offload": "off [fixed]", "rx_gro_hw": "off [fixed]", "tls_hw_record": "off [fixed]"}, "timestamping": ["rx_software", "software"], "hw_timestamp_filters": []}, "ansible_ens5": {"device": "ens5", "macaddress": "16:8e:eb:8b:df:4d", "mtu": 9001, "active": true, "module": "ena", "type": "ether", "pciid": "0000:00:05.0", "promisc": false, "ipv4": {"address": "172.10.1.95", "broadcast": "172.10.1.255", "netmask": "255.255.255.0", "network": "172.10.1.0"}, "ipv6": [{"address": "fe80::148e:ebff:fe8b:df4d", "prefix": "64", "scope": "link"}], "features": {"rx_checksumming": "off [fixed]", "tx_checksumming": "on", "tx_checksum_ipv4": "on", "tx_checksum_ip_generic": "off [fixed]", "tx_checksum_ipv6": "off [fixed]", "tx_checksum_fcoe_crc": "off [fixed]", "tx_checksum_sctp": "off [fixed]", "scatter_gather": "on", "tx_scatter_gather": "on", "tx_scatter_gather_fraglist": "off [fixed]", "tcp_segmentation_offload": "off", "tx_tcp_segmentation": "off [fixed]", "tx_tcp_ecn_segmentation": "off [fixed]", "tx_tcp_mangleid_segmentation": "off [fixed]", "tx_tcp6_segmentation": "off [fixed]", "generic_segmentation_offload": "on", "generic_receive_offload": "on", "large_receive_offload": "off [fixed]", "rx_vlan_offload": "off [fixed]", "tx_vlan_offload": "off [fixed]", "ntuple_filters": "off [fixed]", "receive_hashing": "on", "highdma": "on", "rx_vlan_filter": "off [fixed]", "vlan_challenged": "off [fixed]", "tx_lockless": "off [fixed]", "netns_local": "off [fixed]", "tx_gso_robust": "off [fixed]", "tx_fcoe_segmentation": "off [fixed]", "tx_gre_segmentation": "off [fixed]", "tx_gre_csum_segmentation": "off [fixed]", "tx_ipxip4_segmentation": "off [fixed]", "tx_ipxip6_segmentation": "off [fixed]", "tx_udp_tnl_segmentation": "off [fixed]", "tx_udp_tnl_csum_segmentation": "off [fixed]", "tx_gso_partial": "off [fixed]", "tx_sctp_segmentation": "off [fixed]", "tx_esp_segmentation": "off [fixed]", "tx_udp_segmentation": "off [fixed]", "fcoe_mtu": "off [fixed]", "tx_nocache_copy": "off", "loopback": "off [fixed]", "rx_fcs": "off [fixed]", "rx_all": "off [fixed]", "tx_vlan_stag_hw_insert": "off [fixed]", "rx_vlan_stag_hw_parse": "off [fixed]", "rx_vlan_stag_filter": "off [fixed]", "l2_fwd_offload": "off [fixed]", "hw_tc_offload": "off [fixed]", "esp_hw_offload": "off [fixed]", "esp_tx_csum_hw_offload": "off [fixed]", "rx_udp_tunnel_port_offload": "off [fixed]", "tls_hw_tx_offload": "off [fixed]", "tls_hw_rx_offload": "off [fixed]", "rx_gro_hw": "off [fixed]", "tls_hw_record": "off [fixed]"}, "timestamping": ["tx_software", "rx_software", "software"], "hw_timestamp_filters": []}, "ansible_default_ipv4": {"gateway": "172.10.1.1", "interface": "ens5", "address": "172.10.1.95", "broadcast": "172.10.1.255", "netmask": "255.255.255.0", "network": "172.10.1.0", "macaddress": "16:8e:eb:8b:df:4d", "mtu": 9001, "type": "ether", "alias": "ens5"}, "ansible_default_ipv6": {}, "ansible_all_ipv4_addresses": ["172.17.0.1", "172.10.1.95"], "ansible_all_ipv6_addresses": ["fe80::148e:ebff:fe8b:df4d"], "ansible_apparmor": {"status": "enabled"}, "ansible_date_time": {"year": "2021", "month": "06", "weekday": "Saturday", "weekday_number": "6", "weeknumber": "22", "day": "05", "hour": "14", "minute": "18", "second": "38", "epoch": "1622902718", "date": "2021-06-05", "time": "14:18:38", "iso8601_micro": "2021-06-05T14:18:38.042994Z", "iso8601": "2021-06-05T14:18:38Z", "iso8601_basic": "20210605T141838042994", "iso8601_basic_short": "20210605T141838", "tz": "UTC", "tz_dst": "UTC", "tz_offset": "+0000"}, "ansible_selinux_python_present": true, "ansible_selinux": {"status": "disabled"}, "ansible_dns": {"nameservers": ["127.0.0.53"], "options": {"edns0": true, "trust-ad": true}, "search": ["ec2.internal"]}, "ansible_local": {}, "ansible_python": {"version": {"major": 3, "minor": 8, "micro": 5, "releaselevel": "final", "serial": 0}, "version_info": [3, 8, 5, "final", 0], "executable": "/usr/bin/python3", "has_sslcontext": true, "type": "cpython"}, "ansible_fips": false, "gather_subset": ["all"], "module_setup": true}, "invocation": {"module_args": {"gather_subset": ["all"], "gather_timeout": 10, "filter": [], "fact_path": "/etc/ansible/facts.d"}}}\r\n', b'Shared connection to 3.94.129.121 closed.\r\n')
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b 3.94.129.121 '/bin/sh -c '"'"'rm -f -r /home/ubuntu/.ansible/tmp/ansible-tmp-1622902716.6685963-880-251761966657321/ > /dev/null 2>&1 && sleep 0'"'"''
<3.94.129.121> (0, b'', b'')
ok: [3.94.129.121]
META: ran handlers

TASK [Intilizing Kubernetes Cluster] *******************************************
task path: /home/macharyaainsigh/Easypay-capstone/updatemaster.yml:10
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b 3.94.129.121 '/bin/sh -c '"'"'echo ~ubuntu && sleep 0'"'"''
<3.94.129.121> (0, b'/home/ubuntu\n', b'')
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b 3.94.129.121 '/bin/sh -c '"'"'( umask 77 && mkdir -p "` echo /home/ubuntu/.ansible/tmp `"&& mkdir "` echo /home/ubuntu/.ansible/tmp/ansible-tmp-1622902718.1627135-3632-273224855496762 `" && echo ansible-tmp-1622902718.1627135-3632-273224855496762="` echo /home/ubuntu/.ansible/tmp/ansible-tmp-1622902718.1627135-3632-273224855496762 `" ) && sleep 0'"'"''
<3.94.129.121> (0, b'ansible-tmp-1622902718.1627135-3632-273224855496762=/home/ubuntu/.ansible/tmp/ansible-tmp-1622902718.1627135-3632-273224855496762\n', b'')
Using module file /home/macharyaainsigh/.local/lib/python3.9/site-packages/ansible/modules/command.py
<3.94.129.121> PUT /home/macharyaainsigh/.ansible/tmp/ansible-local-31018ld70xt74/tmpfxj_hpj0 TO /home/ubuntu/.ansible/tmp/ansible-tmp-1622902718.1627135-3632-273224855496762/AnsiballZ_command.py
<3.94.129.121> SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b '[3.94.129.121]'
<3.94.129.121> (0, b'sftp> put /home/macharyaainsigh/.ansible/tmp/ansible-local-31018ld70xt74/tmpfxj_hpj0 /home/ubuntu/.ansible/tmp/ansible-tmp-1622902718.1627135-3632-273224855496762/AnsiballZ_command.py\n', b'')
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b 3.94.129.121 '/bin/sh -c '"'"'chmod u+x /home/ubuntu/.ansible/tmp/ansible-tmp-1622902718.1627135-3632-273224855496762/ /home/ubuntu/.ansible/tmp/ansible-tmp-1622902718.1627135-3632-273224855496762/AnsiballZ_command.py && sleep 0'"'"''
<3.94.129.121> (0, b'', b'')
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b -tt 3.94.129.121 '/bin/sh -c '"'"'sudo -H -S -n  -u root /bin/sh -c '"'"'"'"'"'"'"'"'echo BECOME-SUCCESS-tgabfnbvwtokyzxqyhgkuwxsiigxeqtg ; /usr/bin/python3 /home/ubuntu/.ansible/tmp/ansible-tmp-1622902718.1627135-3632-273224855496762/AnsiballZ_command.py'"'"'"'"'"'"'"'"' && sleep 0'"'"''
Escalation succeeded
<3.94.129.121> (0, b'\r\n{"cmd": ["kubeadm", "init", "--ignore-preflight-errors=Mem"], "stdout": "[init] Using Kubernetes version: v1.21.1\\n[preflight] Running pre-flight checks\\n[preflight] Pulling images required for setting up a Kubernetes cluster\\n[preflight] This might take a minute or two, depending on the speed of your internet connection\\n[preflight] You can also perform this action in beforehand using \'kubeadm config images pull\'\\n[certs] Using certificateDir folder \\"/etc/kubernetes/pki\\"\\n[certs] Generating \\"ca\\" certificate and key\\n[certs] Generating \\"apiserver\\" certificate and key\\n[certs] apiserver serving cert is signed for DNS names [ip-172-10-1-95 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.10.1.95]\\n[certs] Generating \\"apiserver-kubelet-client\\" certificate and key\\n[certs] Generating \\"front-proxy-ca\\" certificate and key\\n[certs] Generating \\"front-proxy-client\\" certificate and key\\n[certs] Generating \\"etcd/ca\\" certificate and key\\n[certs] Generating \\"etcd/server\\" certificate and key\\n[certs] etcd/server serving cert is signed for DNS names [ip-172-10-1-95 localhost] and IPs [172.10.1.95 127.0.0.1 ::1]\\n[certs] Generating \\"etcd/peer\\" certificate and key\\n[certs] etcd/peer serving cert is signed for DNS names [ip-172-10-1-95 localhost] and IPs [172.10.1.95 127.0.0.1 ::1]\\n[certs] Generating \\"etcd/healthcheck-client\\" certificate and key\\n[certs] Generating \\"apiserver-etcd-client\\" certificate and key\\n[certs] Generating \\"sa\\" key and public key\\n[kubeconfig] Using kubeconfig folder \\"/etc/kubernetes\\"\\n[kubeconfig] Writing \\"admin.conf\\" kubeconfig file\\n[kubeconfig] Writing \\"kubelet.conf\\" kubeconfig file\\n[kubeconfig] Writing \\"controller-manager.conf\\" kubeconfig file\\n[kubeconfig] Writing \\"scheduler.conf\\" kubeconfig file\\n[kubelet-start] Writing kubelet environment file with flags to file \\"/var/lib/kubelet/kubeadm-flags.env\\"\\n[kubelet-start] Writing kubelet configuration to file \\"/var/lib/kubelet/config.yaml\\"\\n[kubelet-start] Starting the kubelet\\n[control-plane] Using manifest folder \\"/etc/kubernetes/manifests\\"\\n[control-plane] Creating static Pod manifest for \\"kube-apiserver\\"\\n[control-plane] Creating static Pod manifest for \\"kube-controller-manager\\"\\n[control-plane] Creating static Pod manifest for \\"kube-scheduler\\"\\n[etcd] Creating static Pod manifest for local etcd in \\"/etc/kubernetes/manifests\\"\\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \\"/etc/kubernetes/manifests\\". This can take up to 4m0s\\n[apiclient] All control plane components are healthy after 11.005938 seconds\\n[upload-config] Storing the configuration used in ConfigMap \\"kubeadm-config\\" in the \\"kube-system\\" Namespace\\n[kubelet] Creating a ConfigMap \\"kubelet-config-1.21\\" in namespace kube-system with the configuration for the kubelets in the cluster\\n[upload-certs] Skipping phase. Please see --upload-certs\\n[mark-control-plane] Marking the node ip-172-10-1-95 as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]\\n[mark-control-plane] Marking the node ip-172-10-1-95 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]\\n[bootstrap-token] Using token: 4z1dfb.r7wub35rzuw9r8pk\\n[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles\\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes\\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\\n[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\\n[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\\n[bootstrap-token] Creating the \\"cluster-info\\" ConfigMap in the \\"kube-public\\" namespace\\n[kubelet-finalize] Updating \\"/etc/kubernetes/kubelet.conf\\" to point to a rotatable kubelet client certificate and key\\n[addons] Applied essential addon: CoreDNS\\n[addons] Applied essential addon: kube-proxy\\n\\nYour Kubernetes control-plane has initialized successfully!\\n\\nTo start using your cluster, you need to run the following as a regular user:\\n\\n  mkdir -p $HOME/.kube\\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\\n\\nAlternatively, if you are the root user, you can run:\\n\\n  export KUBECONFIG=/etc/kubernetes/admin.conf\\n\\nYou should now deploy a pod network to the cluster.\\nRun \\"kubectl apply -f [podnetwork].yaml\\" with one of the options listed at:\\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\\n\\nThen you can join any number of worker nodes by running the following on each as root:\\n\\nkubeadm join 172.10.1.95:6443 --token 4z1dfb.r7wub35rzuw9r8pk \\\\\\n\\t--discovery-token-ca-cert-hash sha256:8668ec51dd77b9bbe4026029354fd100ac6b7a2458c49862c35a8c327d2557c9 ", "stderr": "\\t[WARNING Mem]: the system RAM (953 MB) is less than the minimum 1700 MB", "rc": 0, "start": "2021-06-05 14:18:38.503114", "end": "2021-06-05 14:19:13.483668", "delta": "0:00:34.980554", "changed": true, "invocation": {"module_args": {"_raw_params": "kubeadm init  \\"--ignore-preflight-errors=Mem\\"", "_uses_shell": false, "warn": false, "stdin_add_newline": true, "strip_empty_ends": true, "argv": null, "chdir": null, "executable": null, "creates": null, "removes": null, "stdin": null}}}\r\n', b'Shared connection to 3.94.129.121 closed.\r\n')
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b 3.94.129.121 '/bin/sh -c '"'"'rm -f -r /home/ubuntu/.ansible/tmp/ansible-tmp-1622902718.1627135-3632-273224855496762/ > /dev/null 2>&1 && sleep 0'"'"''
<3.94.129.121> (0, b'', b'')
changed: [3.94.129.121] => {
    "changed": true,
    "cmd": [
        "kubeadm",
        "init",
        "--ignore-preflight-errors=Mem"
    ],
    "delta": "0:00:34.980554",
    "end": "2021-06-05 14:19:13.483668",
    "invocation": {
        "module_args": {
            "_raw_params": "kubeadm init  \"--ignore-preflight-errors=Mem\"",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": false
        }
    },
    "rc": 0,
    "start": "2021-06-05 14:18:38.503114",
    "stderr": "\t[WARNING Mem]: the system RAM (953 MB) is less than the minimum 1700 MB",
    "stderr_lines": [
        "\t[WARNING Mem]: the system RAM (953 MB) is less than the minimum 1700 MB"
    ],
    "stdout": "[init] Using Kubernetes version: v1.21.1\n[preflight] Running pre-flight checks\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'\n[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n[certs] Generating \"ca\" certificate and key\n[certs] Generating \"apiserver\" certificate and key\n[certs] apiserver serving cert is signed for DNS names [ip-172-10-1-95 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.10.1.95]\n[certs] Generating \"apiserver-kubelet-client\" certificate and key\n[certs] Generating \"front-proxy-ca\" certificate and key\n[certs] Generating \"front-proxy-client\" certificate and key\n[certs] Generating \"etcd/ca\" certificate and key\n[certs] Generating \"etcd/server\" certificate and key\n[certs] etcd/server serving cert is signed for DNS names [ip-172-10-1-95 localhost] and IPs [172.10.1.95 127.0.0.1 ::1]\n[certs] Generating \"etcd/peer\" certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [ip-172-10-1-95 localhost] and IPs [172.10.1.95 127.0.0.1 ::1]\n[certs] Generating \"etcd/healthcheck-client\" certificate and key\n[certs] Generating \"apiserver-etcd-client\" certificate and key\n[certs] Generating \"sa\" key and public key\n[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n[kubeconfig] Writing \"admin.conf\" kubeconfig file\n[kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Starting the kubelet\n[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\n[control-plane] Creating static Pod manifest for \"kube-scheduler\"\n[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s\n[apiclient] All control plane components are healthy after 11.005938 seconds\n[upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n[kubelet] Creating a ConfigMap \"kubelet-config-1.21\" in namespace kube-system with the configuration for the kubelets in the cluster\n[upload-certs] Skipping phase. Please see --upload-certs\n[mark-control-plane] Marking the node ip-172-10-1-95 as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]\n[mark-control-plane] Marking the node ip-172-10-1-95 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]\n[bootstrap-token] Using token: 4z1dfb.r7wub35rzuw9r8pk\n[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n[kubelet-finalize] Updating \"/etc/kubernetes/kubelet.conf\" to point to a rotatable kubelet client certificate and key\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nAlternatively, if you are the root user, you can run:\n\n  export KUBECONFIG=/etc/kubernetes/admin.conf\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 172.10.1.95:6443 --token 4z1dfb.r7wub35rzuw9r8pk \\\n\t--discovery-token-ca-cert-hash sha256:8668ec51dd77b9bbe4026029354fd100ac6b7a2458c49862c35a8c327d2557c9 ",
    "stdout_lines": [
        "[init] Using Kubernetes version: v1.21.1",
        "[preflight] Running pre-flight checks",
        "[preflight] Pulling images required for setting up a Kubernetes cluster",
        "[preflight] This might take a minute or two, depending on the speed of your internet connection",
        "[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'",
        "[certs] Using certificateDir folder \"/etc/kubernetes/pki\"",
        "[certs] Generating \"ca\" certificate and key",
        "[certs] Generating \"apiserver\" certificate and key",
        "[certs] apiserver serving cert is signed for DNS names [ip-172-10-1-95 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.10.1.95]",
        "[certs] Generating \"apiserver-kubelet-client\" certificate and key",
        "[certs] Generating \"front-proxy-ca\" certificate and key",
        "[certs] Generating \"front-proxy-client\" certificate and key",
        "[certs] Generating \"etcd/ca\" certificate and key",
        "[certs] Generating \"etcd/server\" certificate and key",
        "[certs] etcd/server serving cert is signed for DNS names [ip-172-10-1-95 localhost] and IPs [172.10.1.95 127.0.0.1 ::1]",
        "[certs] Generating \"etcd/peer\" certificate and key",
        "[certs] etcd/peer serving cert is signed for DNS names [ip-172-10-1-95 localhost] and IPs [172.10.1.95 127.0.0.1 ::1]",
        "[certs] Generating \"etcd/healthcheck-client\" certificate and key",
        "[certs] Generating \"apiserver-etcd-client\" certificate and key",
        "[certs] Generating \"sa\" key and public key",
        "[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"",
        "[kubeconfig] Writing \"admin.conf\" kubeconfig file",
        "[kubeconfig] Writing \"kubelet.conf\" kubeconfig file",
        "[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file",
        "[kubeconfig] Writing \"scheduler.conf\" kubeconfig file",
        "[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"",
        "[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"",
        "[kubelet-start] Starting the kubelet",
        "[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"",
        "[control-plane] Creating static Pod manifest for \"kube-apiserver\"",
        "[control-plane] Creating static Pod manifest for \"kube-controller-manager\"",
        "[control-plane] Creating static Pod manifest for \"kube-scheduler\"",
        "[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"",
        "[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s",
        "[apiclient] All control plane components are healthy after 11.005938 seconds",
        "[upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace",
        "[kubelet] Creating a ConfigMap \"kubelet-config-1.21\" in namespace kube-system with the configuration for the kubelets in the cluster",
        "[upload-certs] Skipping phase. Please see --upload-certs",
        "[mark-control-plane] Marking the node ip-172-10-1-95 as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]",
        "[mark-control-plane] Marking the node ip-172-10-1-95 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]",
        "[bootstrap-token] Using token: 4z1dfb.r7wub35rzuw9r8pk",
        "[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles",
        "[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes",
        "[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials",
        "[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token",
        "[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster",
        "[bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace",
        "[kubelet-finalize] Updating \"/etc/kubernetes/kubelet.conf\" to point to a rotatable kubelet client certificate and key",
        "[addons] Applied essential addon: CoreDNS",
        "[addons] Applied essential addon: kube-proxy",
        "",
        "Your Kubernetes control-plane has initialized successfully!",
        "",
        "To start using your cluster, you need to run the following as a regular user:",
        "",
        "  mkdir -p $HOME/.kube",
        "  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config",
        "  sudo chown $(id -u):$(id -g) $HOME/.kube/config",
        "",
        "Alternatively, if you are the root user, you can run:",
        "",
        "  export KUBECONFIG=/etc/kubernetes/admin.conf",
        "",
        "You should now deploy a pod network to the cluster.",
        "Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:",
        "  https://kubernetes.io/docs/concepts/cluster-administration/addons/",
        "",
        "Then you can join any number of worker nodes by running the following on each as root:",
        "",
        "kubeadm join 172.10.1.95:6443 --token 4z1dfb.r7wub35rzuw9r8pk \\",
        "\t--discovery-token-ca-cert-hash sha256:8668ec51dd77b9bbe4026029354fd100ac6b7a2458c49862c35a8c327d2557c9 "
    ]
}

TASK [pause] *******************************************************************
task path: /home/macharyaainsigh/Easypay-capstone/updatemaster.yml:13
Pausing for 30 seconds
(ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
ok: [3.94.129.121] => {
    "changed": false,
    "delta": 30,
    "echo": true,
    "rc": 0,
    "start": "2021-06-05 14:19:13.645190",
    "stderr": "",
    "stdout": "Paused for 30.0 seconds",
    "stop": "2021-06-05 14:19:43.645396",
    "user_input": ""
}

TASK [Create directory for kube config.] ***************************************
task path: /home/macharyaainsigh/Easypay-capstone/updatemaster.yml:14
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b 3.94.129.121 '/bin/sh -c '"'"'echo ~ubuntu && sleep 0'"'"''
<3.94.129.121> (0, b'/home/ubuntu\n', b'')
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b 3.94.129.121 '/bin/sh -c '"'"'( umask 77 && mkdir -p "` echo /var/tmp `"&& mkdir "` echo /var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714 `" && echo ansible-tmp-1622902783.7061539-20943-229807305399714="` echo /var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714 `" ) && sleep 0'"'"''
<3.94.129.121> (0, b'ansible-tmp-1622902783.7061539-20943-229807305399714=/var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714\n', b'')
Using module file /home/macharyaainsigh/.local/lib/python3.9/site-packages/ansible/modules/file.py
<3.94.129.121> PUT /home/macharyaainsigh/.ansible/tmp/ansible-local-31018ld70xt74/tmph2l8uzpl TO /var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714/AnsiballZ_file.py
<3.94.129.121> SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b '[3.94.129.121]'
<3.94.129.121> (0, b'sftp> put /home/macharyaainsigh/.ansible/tmp/ansible-local-31018ld70xt74/tmph2l8uzpl /var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714/AnsiballZ_file.py\n', b'')
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b 3.94.129.121 '/bin/sh -c '"'"'setfacl -m u:ansible:r-x /var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714/ /var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714/AnsiballZ_file.py && sleep 0'"'"''
<3.94.129.121> (127, b'', b'/bin/sh: 1: setfacl: not found\n')
<3.94.129.121> Failed to connect to the host via ssh: /bin/sh: 1: setfacl: not found
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b 3.94.129.121 '/bin/sh -c '"'"'chmod u+x /var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714/ /var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714/AnsiballZ_file.py && sleep 0'"'"''
<3.94.129.121> (0, b'', b'')
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b 3.94.129.121 '/bin/sh -c '"'"'chown ansible /var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714/ /var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714/AnsiballZ_file.py && sleep 0'"'"''
<3.94.129.121> (1, b'', b"chown: changing ownership of '/var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714/': Operation not permitted\nchown: changing ownership of '/var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714/AnsiballZ_file.py': Operation not permitted\n")
<3.94.129.121> Failed to connect to the host via ssh: chown: changing ownership of '/var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714/': Operation not permitted
chown: changing ownership of '/var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714/AnsiballZ_file.py': Operation not permitted
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b 3.94.129.121 '/bin/sh -c '"'"'chmod +a '"'"'"'"'"'"'"'"'ansible allow read,execute'"'"'"'"'"'"'"'"' /var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714/ /var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714/AnsiballZ_file.py && sleep 0'"'"''
<3.94.129.121> (1, b'', b"chmod: invalid mode: \xe2\x80\x98+a\xe2\x80\x99\nTry 'chmod --help' for more information.\n")
<3.94.129.121> Failed to connect to the host via ssh: chmod: invalid mode: ‘+a’
Try 'chmod --help' for more information.
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b 3.94.129.121 '/bin/sh -c '"'"'chmod A+user:ansible:rx:allow /var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714/ /var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714/AnsiballZ_file.py && sleep 0'"'"''
<3.94.129.121> (1, b'', b"chmod: invalid mode: \xe2\x80\x98A+user:ansible:rx:allow\xe2\x80\x99\nTry 'chmod --help' for more information.\n")
<3.94.129.121> Failed to connect to the host via ssh: chmod: invalid mode: ‘A+user:ansible:rx:allow’
Try 'chmod --help' for more information.
<3.94.129.121> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<3.94.129.121> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="../aws-private.pem"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="ubuntu"' -o ConnectTimeout=10 -o ControlPath=/home/macharyaainsigh/.ansible/cp/177154190b 3.94.129.121 '/bin/sh -c '"'"'rm -f -r /var/tmp/ansible-tmp-1622902783.7061539-20943-229807305399714/ > /dev/null 2>&1 && sleep 0'"'"''
<3.94.129.121> (0, b'', b'')
fatal: [3.94.129.121]: FAILED! => {
    "msg": "Failed to set permissions on the temporary files Ansible needs to create when becoming an unprivileged user (rc: 1, err: chmod: invalid mode: ‘A+user:ansible:rx:allow’\nTry 'chmod --help' for more information.\n}). For information on working around this, see https://docs.ansible.com/ansible/2.11/user_guide/become.html#becoming-an-unprivileged-user"
}

PLAY RECAP *********************************************************************
3.94.129.121               : ok=3    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

